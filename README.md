# Emotion-Based-Music-Player

This is a music player which will first recognize the emotion on your face. Then according to the recognized emotion, it will play the best song suited for you. This project has been developed using Python and OpenCV.

# Dataset
In this project, I have used the CK+ dataset. Here is the link to download the dataset http://www.consortium.ri.cmu.edu/ckagree/. This dataset has 327 images. Once you have downloaded the dataset, extract it and look at the readme. It is organised into two folders, one containing images, the other containing the txt files with emotions encoded that correspond to the kind of emotion shown. From the readme of the dataset, the encoding is: {0=neutral, 1=anger, 2=contempt, 3=disgust, 4=fear, 5=happy, 6=sadness, 7=surprise}. To this dataset, I have appended few of my own images, which I captures from the webcam. Also, I searched for a few images from the google and added them to the dataset. My dataset was about 1000 images.

# Steps
1.First I organised the dataset. In the directory you are working in, make two folders called “source_emotion” and “source_images”. Extract the dataset and put all folders containing the txt files in a folder called “source_emotion”. Put the folders containing the images in a folder called “source_images”. Also create a folder named “sorted_set”, and within it, create folders for the emotion labels (“neutral”, “anger”, etc.). Each image sequence consists of the forming of an emotional expression, starting with a neutral face and ending with the emotion. So, from each image sequence we want to extract two images; one neutral (the first image) and one with an emotional expression (the last image). The script inside sort_dataset.py does this step.

2. For the classifier we need to find the face on each image, convert to grayscale, crop it and save the image to the dataset. I have used a HAAR filter from OpenCV for detecting the faces. OpenCV provides 4 pre-trained classifier. To detect as many faces as possible I used all of them in sequence, and aborted the face search once I found one. I have added the filters as well in the directory OpenCV_FaceCascade/. Create another folder called “dataset”, and create subfolders for each emotion (“neutral”, “anger”, etc.) in it. Then, detect, crop and save face. The face_extractor.py script does that for you.

3. The dataset is ready. Now, the next step is to train our emotion classifier using the dataset and test it. The classifier used by me is LBPHFace recognizer which is provided by OpenCV. LBPH Stands for Local Binary Patterns Histogram. You can read more about LBPH on https://towardsdatascience.com/face-recognition-how-lbph-works-90ec258c3d6b. This classifier is used for face recognition and finding the characteristic features on the face. We also need to divide our dataset into training and test sets. I have used 80% of the images for training and 20% for testing. I have added a script which does both training and testing and gives the final accuracy of the model. You can find it under run.py.  Also, for convenience I have added a train.py script which has the code for training the model. In my final script I have used only 4 emotions viz. anger, sad, happy and neutral; since these are the ones that will matter in my music player later. The model have a test accuracy of about 73.2% on my dataset (CK+ dataset + google images + my own images). Make sure that the number of train images for each of the emotion categories is more or less equal in number.

4. Finally, we need to predict the emotion on the face of the user when he opens his laptop. So we need to use the webcam of our PC for getting the face of the person in front of it. So, I have added a small script called webcam.py for reference. In that, I have written a small script for checking whether the webcam works as needed.

5. The final step is to suggest the song to the user which will suit his mood the best. I have added that script inside the file predict.py. In final script, I use only three emotions namely anger, sad and happy. I have created an excel file which has a list of 5 songs(paths to them in your system) for each of these emotions in their respective columns. So, when the emotion is recognized an appropriate song from the file is played (provided the path given by you is actually a song). 

So, here it is. Emotion-Aware music player
